\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{../fa-style}
% \usepackage[utf8]{inputenc}

% include proofs of trivial facts
% see TRIVIA environment in fa-style.sty
\def\TRIVIAPROOFS{}{}

\title{Spectra of rank-1 operators. All-ones matrix and its perturbations}
\date{October 18, 2016}
\author{rn}

\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Background}
The purpose of this work is to introduce the language, equations
and the ideology of the method of similar operators.
It is accomplished by considering rather simplistic example
of the matrix almost all entries of which are unities
and the rest are zeroes.
Though simple and naive, this example goes through main steps of the general schema
and forms the ground for future research.

\section{Intro. Operator representation}
Let \( A: \mathscr X\to\mathscr X \) be a linear operator of the rank 1
(\( \rank A = \dim\img A = 1 \)).

\begin{propose}
    Such an opererator can be represented in the form \( A x = \xi(x) a \)
    where \( \xi\in\mathscr X^* \) is a linear form, \( 0\neq a \in\mathscr X \).
    \( \spec A = \{0, \xi(a)\} \) if \( \dim\mathscr X > 1 \), otherwise \( \spec A = \{\xi(a)\} \).
\end{propose}

\section{Matrix of ones}
Let \( \matr{N}{\RR} \) denote an algebra of square matrices of dimension \( N \) over field \( \RR \),
with usual operations of addition and multiplication.
Consider \( \allones{N} \in \matr{N}{\RR} \)
--- a matrix of dimension \( N \) whose all entries are ones:
\[\allones{N} =
\begin{pmatrix}
    1      & 1      & \cdots & 1 \\
    1      & 1      & \cdots & 1 \\
    \vdots & \vdots & \ddots & \vdots \\
    1      & 1      & \cdots & 1
\end{pmatrix}\]

The operator defined by \( \allones{N} \) is of rank \( 1 \).

\begin{propose}
    \[\allones{N}^2 =
    \begin{pmatrix}
        N      & \cdots & N \\
        \vdots & \ddots & \vdots \\
        N      & \cdots & N
    \end{pmatrix} = N \allones{N}\]

    And
    \( \allones{N}^k = N^{k-1} \allones{N} \)
\end{propose}

\begin{propose}
    Let \( N>1 \).
    The minimal polynomial \( p \) of \( \allones{N} \) is given by formula
    \[p(\lambda) = \lambda^2 - N \lambda\]

    And the spectra of \( \allones{N} \) consists of the roots of \( p \):
    \[\sigma(\allones{N}) = \{ 0, N \}\]
\end{propose}

\begin{dfn}{Similar matrices}
    Two matrices \( \mathcal Y, \mathcal Z \in\matr{N}{\RR} \) are called similar,
    if there is invertible matrix \( \mathcal V\in\matr{N}{\RR} \) such that
    \[\mathcal V^{-1}\mathcal Y\mathcal V = \mathcal Z\]
\end{dfn}
\begin{propose}
    Similar matrices have the same spectra
\end{propose}

Let \( \eigenspace{\mathcal A}{\lambda} \) denote the eigenspace of the matrix \( \mathcal A \)
corresponding to the eigenvalue \( \lambda \).

\begin{propose}
    \[\eigenspace{\allones{N}}{N} = \linspan{f_0}\]
    \[f_0 = \begin{pmatrix} \frac{1}{\sqrt N} & \cdots & \frac{1}{\sqrt N} \end{pmatrix}^\transposed\]

        where \( \linspan{v_1, \ldots, v_n} \) denotes the linear span of the vectors \( v_1, \ldots, v_n \).
\end{propose}

As for zero, its eigenspace consists exactly of these vectors,
for which the sum of the coordinates equals zero.
Choose the basis in \( \eigenspace{\allones{N}}{0} \) as
\[
h_1 = \begin{pmatrix}1 \\ -1 \\ 0 \\ \vdots \\ 0\end{pmatrix}
    h_2 = \begin{pmatrix}0 \\ 1 \\ -1 \\ 0 \\ \vdots \\ 0\end{pmatrix}
        h_{n-1} = \begin{pmatrix}0 \\ \vdots \\ 0 \\ 1 \\ -1 \end{pmatrix}\]

            We can orthonormalize it then:

\[f_1 = h_1 / \norm{h_1} =
\begin{pmatrix}\frac{1}{\sqrt2} & - \frac{1}{\sqrt2} & 0 & \cdots & 0 \end{pmatrix}^\transposed\]

    \[g_2 = h_2 - \left(h_2|f_1\right)f_1 =
\begin{pmatrix}0\\ 1\\ -1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}
    -
\frac{-1}{\sqrt2} \begin{pmatrix} 1/\sqrt2 \\ - 1/\sqrt2 \\ 0 \\ 0 \\ \vdots \\ 0 \end{pmatrix}
    = \begin{pmatrix} 1/2 \\ 1/2 \\ -1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}\]

        \[f_2 = g_2/\norm{g_2} =
g_2 \frac{1}{\sqrt{4/3}} =
\begin{pmatrix} \frac1{\sqrt6} & \frac1{\sqrt6} & - \frac2{\sqrt6} & 0 & \cdots & 0 \end{pmatrix}^\transposed\]

    \[g_3 =
h_3 - \underbrace{\left(h_3|f_1\right)}_{=0}f_1
    - \underbrace{\left(h_3|f_2\right)}_{=-\sqrt{\frac23}}f_2
= \begin{pmatrix} 1/3 & 1/3 & 1/3 & -1 & 0 & \cdots & 0 \end{pmatrix}^\transposed\]

    \[f_3 = g_3 / \norm{g_3} = g_3 \frac{1}{\sqrt{1/3 + 1}} =
\begin{pmatrix}
    \frac{1}{2\sqrt3} & \frac{1}{2\sqrt3} &
    \frac{1}{2\sqrt3} & - \frac{3}{2\sqrt3} &
    0 & \cdots & 0
\end{pmatrix}^\transposed\]

So suppose that first \( m \) vectors of this orthonormal system
are of the form

\[ f_k =
\begin{pmatrix}
    a_k & \cdots & a_k & b_k & 0 & \cdots & 0
\end{pmatrix}^\transposed\]
i.e. the first \( k \) elements of the vector all equal the same \( a_k \)
and \( (k+1) \)'st is the \( b_k = -ka_k \) closing the sequence.
This is true at least for first 3 vectors.
At the same time \( h_{k+1} \) has all zeroes
except \( (k+1) \)'st and \( (k+2) \)'nd entries which are \( 1 \) and \( -1 \) respectively.
Hence \( \left(h_k|f_{k-1}\right) = b_{k-1} \) and \( \left(h_k|f_j\right) = 0 \) for \( j < k-1 \).
That gives

\[g_k = h_k - \left(h_k|f_{k-1}\right) f_{k-1} =
\begin{pmatrix}
    - a_{k-1} b_{k-1} \\
    \vdots \\
    - a_{k-1} b_{k-1} \\
    1 - b_{k-1}^2     \\
    -1 \\
    0 \\
    \vdots \\
    0
\end{pmatrix}\]

One can also note that (TODO: prove)
\[1 - b_{k-1}^2 = - a_{k-1} b_{k-1} \text{ for } k>1\]

Thus
\[g_k =
\begin{pmatrix}
    - a_{k-1} b_{k-1} \\
    \vdots \\
    - a_{k-1} b_{k-1} \\
    -1 \\
    0 \\
    \vdots \\
    0
\end{pmatrix}\]

Norm of this vector can be calculated as

\providecommand{\fknorm}{\sqrt{k a_{k-1}^2 b_{k-1}^2 + 1}}
\[\norm{g_k} = \fknorm\]

Now that \( b_k = -(k-1)a_k \)

\renewcommand{\fknorm}{\sqrt{k(k-1)^2 a_{k-1}^4 + 1}}
\[\norm{g_k} = \fknorm\]

If \( a_k = 1/c_k \) then the closing entry is \( b_k = -k/c_k \).
Also \( b_k \) always equals \( -1/\norm{g_k} = \frac{-k}{k\norm{g_k}} \).
That yields immediately

\begin{propose}
    \[a_k = \frac{1}{k\fknorm}\]
    \[f_k =
    \begin{pmatrix}a_k \\ \vdots \\ a_k \\ -ka_k \\ 0 \\ \vdots \\ 0 \end{pmatrix} =
    \frac{1}{k\fknorm}
    \begin{pmatrix}1 \\ \vdots \\ 1 \\ -k \\ 0 \\ \vdots \\ 0 \end{pmatrix}\]
        for \( k=\overline{2,N-1} \).

    \[f_1
    = \begin{pmatrix}a_1 \\ -a_1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}
        = \begin{pmatrix}\frac1{\sqrt2} \\ - \frac{1}{\sqrt2} \\ 0 \\ \vdots \\ 0 \end{pmatrix}
            \]
    \[\eigenspace{\allones{N}}{0} = \{ f_1, \ldots, f_{n-1} \}\]

    \( \allones{N} \) is similar to
    \[\begin{pmatrix}
        N &   &        & \\
        & 0 &        & \\
        &   & \ddots & \\
        &   &        & 0
    \end{pmatrix}\]

    And the transformation matrix that diagonalizes \( \allones{N} \) is
    \[\mathcal T =
    \begin{pmatrix}
        1/\sqrt N &  1/\sqrt2 & 1/\sqrt6  & 1/2\sqrt3  & \cdots & a_{n-1} \\
        \vdots    & -1/\sqrt2 & 1/\sqrt6  & 1/2\sqrt3  & \cdots & a_{n-1} \\
        \vdots    & 0         & -2/\sqrt6 & 1/2\sqrt3  & \cdots & a_{n-1} \\
        \vdots    & \vdots    & 0         & -3/2\sqrt3 & \cdots & a_{n-1} \\
        \vdots    & \vdots    & \vdots    & 0          & \cdots & a_{n-1} \\
        \vdots    & \vdots    & \vdots    & \vdots     & \ddots & \vdots  \\
        \vdots    & \vdots    & \vdots    & \vdots     & \cdots & a_{n-1} \\
        1/\sqrt N & 0         & 0         & 0          & \cdots & -(n-1)a_{n-1}
    \end{pmatrix}\]

    Composed of orthonormal real column vectors, this matrix is \emph{unitary}
    and thus \( \mathcal T^{-1} = \mathcal T^\conjtransposed = \mathcal T^\transposed \),
    \( \det\mathcal T = 1 \).
\end{propose}


\section{Almost-all-ones matrix}
Let \( \almostallones{M}{N}\in\matr{N}{\RR} \), be a matrix of dimension \( N \)
comprised of \( M \) zeroes and \( N^2 - M \) unities.
And let \( M \) be small in some sense to be determined later.

\( \almostallones{M}{N} \) can be represented as
\[
\almostallones{M}{N} = \allones{N} - \perturbmatrix{M}{N}
\footnote{used notation is a bit messy, since neither \( \almostallones MN \) or \( \perturbmatrix MN \) can be determined solely by \( N \) and \( M \)}
\]

Where \( \perturbmatrix MN \) (hereafter called perturbation matrix) has unities exactly at these places, where \( \almostallones MN \) has zeroes.

Consider the task of localization of the eigenvalues of \( \almostallones{M}{N} \).

We'll deduce bounds for eigenvalues of \( \almostallones{M}{N} \)
in terms of its two characteristics: the dimension \( N \) and number of zeroes \( M \).

\subsection{Reduction to the method of similar operators}

\begin{propose}
    Similar matrices have the same spectra
\end{propose}

It is clear that \( \almostallones{M}{N} \) is similar to the matrix \( \mathcal A - \mathcal B \) where
\[\mathcal A = \transformmatrix{\mathcal T}{\allones{N}}
= \begin{pmatrix}
    N &   &        & \\
      & 0 &        & \\
      &   & \ddots & \\
      &   &        & 0
\end{pmatrix}\]
\[\mathcal B = \transformmatrix{\mathcal T}{\perturbmatrix{M}{N}}\]


We're going to use the operators language (just for convenience and consistency with related papers).

\( \Hom{\mathscr Y}{\mathscr Z} \) denotes the space of continuous linear operators
from \( \mathscr Y \) to \( \mathscr Z \),
\( \End{\mathscr Y} = \Hom{\mathscr Y}{\mathscr Y} \) is an algebra of continuous linear operators on \( Y \).
The norm in \( \Hom{\mathscr Y}{\mathscr Z} \) and \( \End{\mathscr Y} \) is the usual operator norm:
\[\norm X = \sup_{\norm x = 1}{\norm{X x}}\]
\begin{dfn}{Similar operators}
    Two operators \( Y_j:\dom{Y_j}\subset\mathscr Y_j\to\mathscr Z_j, j=\overline{1,2} \) are called similar,
    if there is invertible map \( V\in\Hom{\mathscr Y_2}{\mathscr Y_1} \),
    such that \( V(\dom{Y_2}) = \dom{Y_1} \) and
    \[Y_1 V y = V Y_2 y \text{ for every } y\in\dom{Y_2}\]
\end{dfn}
\begin{propose}
    Similar operators have the same spectra
\end{propose}

Let \( \mathscr X \) denote the Banach space \( \RR^N \) with the euclid norm
\( \norm x = \sqrt{\sum_{j=1}^N x_{(j)}^2} \), where \( x_{(j)} \) are coordinates of \( x \) in chosen basis.

\( \mathscr X = \mathscr X_1 \oplus \mathscr X_2 \),
\( \mathscr X_1 = \eigenspace{\allones{N}}{N} \),
\( \mathscr X_2 = \eigenspace{\allones{N}}{0} \).
\( P_1, P_2 \) will denote projections performing the above decomposition:
every \( x\in\mathscr X \) can be uniquely represented as \( x = x_1 + x_2, x_j\in\mathscr X_j,j=\overline{1,2} \)
and we define \( P_j x = x_j \), \( j=\overline{1,2} \).

Projections \( P_j \) also decompose \( \End{\mathscr X} \) into
\( \Hom{\mathscr X_1}{\mathscr X_1}
    \oplus \Hom{\mathscr X_1}{\mathscr X_2}
    \oplus \Hom{\mathscr X_2}{\mathscr X_1}
    \oplus \Hom{\mathscr X_2}{\mathscr X_2} \).

For every operator \( X\in\Hom{\mathscr X_i}{\mathscr X_j} \)
let \( X_{ij} \in \Hom{\mathscr X_j}{\mathscr X_i} \)
denote the restriction of \( P_i X P_j \) to \( \mathscr X_j \) with codomain \( \mathscr X_i \).
\( X \) can be represented by operators matrix:
\[X \sim \begin{pmatrix}
    X_{11} & X_{12} \\
    X_{21} & X_{22}
\end{pmatrix}\]
which acts on every \( x = x_1 \oplus x_2, x_j\in\mathscr X_j,j=\overline{1,2} \) the following way:
\[
X x \sim
\begin{pmatrix}
    X_{11} & X_{12} \\
    X_{21} & X_{22}
\end{pmatrix}
\begin{pmatrix} x_1 \\ x_2 \end{pmatrix}
= \begin{pmatrix}
    X_{11} x_1 + X_{12} x_2 \\
    X_{21} x_1 + X_{22} x_2
\end{pmatrix}
\]


Let \( A \) and \( B \) be operators defined by matrices \( \mathcal A, \mathcal B \) respectively.
The operator \( A \) is called undisturbed and \( B \) is called a perturbation.
We're estimating eigenvalues of the operator \( A - B \).

Following the general schema, we introduce
the space of admissible perturbations \( \mathfrak U \) (\( B\in\mathfrak U \))
such that \( B \in \mathfrak U \)
and since we can't have any knowledge about \( B \) (because of the way it is constructed)
we define \( \mathfrak U \) be just \( \End{\mathscr X} \).
We'll be searching for an operator similar to \( A - B \)
in the form \( A - JX \) with the similarity transformation \( I + \Gamma X \),
where \( J, \Gamma \in \End{\mathfrak U} \) are transformators to be chosen.
The intuition is that \( A - JX \) should have simpler structure compared to \( A-B \).
Specifically, our task is to find \( X \) satisfying equation

\begin{equation}\label{eq:simopmain}
    (A - B)(I + \Gamma X) = (I + \Gamma X)(A - JX)
\end{equation}

\( \Gamma X \) is defined to satisfy equation

\begin{equation}
\label{eq:gammadef}
    A\Gamma X - (\Gamma X) A = X - JX
\end{equation}

Where \( A\Gamma X - (\Gamma X) A = \ad{A}{\Gamma X} \) and \( \ad{A}{} \) is the operator of commutation with \( A \)

If
\[
    \Gamma X \sim
    \begin{pmatrix}
        \gamma_{11}(X) & \gamma_{12}(X) \\
        \gamma_{21}(X) & \gamma_{22}(X)
    \end{pmatrix}
    \]
Then
\[
    \ad{A}{\Gamma X} \sim
    \frac1N
    \begin{pmatrix}
        0 & \gamma_{12}(X) \\
        - \gamma_{21}(X) & 0
    \end{pmatrix}
    \]

The equality \eqref{eq:gammadef} will hold and \( JX \) will be diagonal if we chose
\[
    JX = P_1 X P_1 + P_2 X P_2 \sim
    \begin{pmatrix}
        X_{11} & 0 \\
        0      & X_{22}
    \end{pmatrix}
    \]

\[
    \Gamma X = \frac{1}{N} (P_1 X P_2 - P_2 X P_1) \sim
    \frac{1}{N}
    \begin{pmatrix}
        0       & X_{12} \\
        -X_{21} & 0
    \end{pmatrix}
    \]

Now we need to find such \( X \) that
\begin{equation}\label{eq:similarity1}
    (A - B)(I + \Gamma X) - (I + \Gamma X)(A - JX) = 0
\end{equation}

\[\begin{aligned}
    & (A - B)(I + \Gamma X) - (I + \Gamma X)(A - JX) = \\
    & = A - B + A\Gamma X - B\Gamma X - A + JX - (\Gamma X) A + (\Gamma X) JX = \\
    & = X - B - B\Gamma X + (\Gamma X) JX = 0
\end{aligned}\]
\begin{equation}\label{eq:similarity2}
    X = B + B\Gamma X - (\Gamma X) JX
\end{equation}

Applying \( J \) to both sides of the last equation we get
\[\eqref{eq:similarity2} \implies
JX = JB + J(B\Gamma X)\]

And substituting this expression for \( JX \) back into \eqref{eq:similarity2}:

\begin{equation}\label{eq:similarity}
    X = \Phi(X) \eqdef B - (\Gamma X) JB + B\Gamma X - (\Gamma X) J(B\Gamma X)
\end{equation}

This is the equation we'll be working with

\subsection{Solution of nonlinear equation}
\( \Phi:\mathfrak U\to\mathfrak U \) is a (second order) nonlinear operator.
We'll solve equation \eqref{eq:similarity}
by showing that \( \Phi \) is a contraction in some ball \( \{ X\in \mathfrak U; \norm{X} \leq \varepsilon \} \) (\( \varepsilon>0 \))
and applying fix-point theorem.

Let \( B_0, T \) be an operator defined by the original perturbation matrix \( \perturbmatrix{M}{N} \)
and transformation operator defined by matrix \( \mathcal T \) respectively.

Let \( \normex{2}{.} \) denote the norm in \( \matr{N}{\RR} \) given by
\[\normex{2}{\mathcal Y} = \sqrt{\sum_{i,j=1}^N y_{ij}^2} \quad\text{ for every } \mathcal Y = \left(y_{ij}\right) \in \matr{N}{\RR}\]
\begin{lemma}
    \[\norm T = \norm{T^{-1}} = \norm J = \norm{P_1} = \norm{P_2} = 1\]
    \[\normex{2}{\perturbmatrix{M}{N}} = \sqrt{M} \leq N\]
    \[\norm B = \norm{B_0} \leq \sqrt M\]
    \[\norm{\Gamma} = \frac{1}{N}\]
\end{lemma}
\begin{proof}
    \( T \) is unitary, \( J, P_1, P_2 \) are projections, and their norms are equal 1.
    Operator \( B_0 \) is defined by matrix \( \perturbmatrix{M}{N} = \left(b_{ij}\right), b_{ij}\in\{0,1\} \),
    so if \( \norm x = 1 \)
    \[
        \begin{split}
            \norm{B_0 x} &= \norm{\sum_{i=0}^N \left(\sum_{j=0}^N b_{ij} x_j\right) e_i}
            = \sqrt{\sum_i \left(\sum_j b_{ij} x_j\right)^2} \\
            &\leq \sqrt{\sum_i \left(\sum_j (b_{ij} x_j)^2\right)}
            \leq \sqrt{\sum_{ij} b_{ij}^2} \eqdef \sqrt M
        \end{split}
    \]
The number \( M \) of unities in \( \perturbmatrix{M}{N} \) is less than \( N^2 \) by construction.
\[\norm B = \norm{T^{-1} B_0 T} \underbrace{=}_{T \text{ is isometric}} \norm{B_0} \leq \sqrt M\]
    Finally, if \( \norm X = 1 \), \( \norm x = 1 \)
    \[\sup\norm{\Gamma X x} = \frac1N \sup\norm{\begin{pmatrix}X_{12}x_2 \\ -X_{21}x_1\end{pmatrix}}
                            = \frac1N\]
    so \( \norm\Gamma = \frac1N \)
\end{proof}

First we show that there is a ball in \( \mathfrak U \) centered at \( 0 \)
which is mapped by \( \Phi \) into itself.

To show that
means to show that there is such \( r>0 \) that
\[\norm{\Phi(X)} \leq r \text{ whenever } \norm{X}\leq r\]

    \begin{align*}
        \norm{\Phi(X)} &=    \norm{B + B\Gamma X - (\Gamma X) JB - (\Gamma X)J(B\Gamma X)} \\
                     &\leq \norm{B} + \norm{B}\norm{\Gamma} \norm{X} + \norm{\Gamma}\norm{X}\norm{J}\norm{B} + \norm{\Gamma}^2\norm{J}\norm{B}\norm{X}^2 \\
                     & = \norm{\Gamma}^2\norm{B}\norm{X}^2 + 2\norm{B}\norm{\Gamma}\norm{X} + \norm{B}
    \end{align*}
    \begin{equation}
        \label{eq:phi_norm_b1}
        \norm{\Phi(X)}
        \leq
            \gamma^2\beta r^2 + 2\gamma\beta r + \beta
            \quad \text{ for every } \gamma\geq\norm{\Gamma}, \beta\geq\norm{B}, r\geq\norm{X}
    \end{equation}

    It would show that \( \Phi \) maps ball of radius \( r \) into itself
    if we found such \( \gamma\geq\norm{\Gamma}, \beta\geq\norm{B}, r>0 \)
    that
\begin{equation}\label{eq:phi_endo0}
    \gamma^2\beta r^2 + (2\gamma\beta - 1) r + \beta \leq 0
\end{equation}

This equation has real solutions if
\begin{equation}\label{eq:phi_endo1}
    \gamma\beta\leq\frac14
\end{equation}

We can use these three inequalities \eqref{eq:phi_norm_b1} \eqref{eq:phi_endo0} \eqref{eq:phi_endo1}
for retrieving different convergence conditions based on different bounds for norms of \( B \).
For now we'll use rough estimates from the last lemma.

\begin{lemma}
    If \( r \) lies between the two roots of \eqref{eq:phi_endo0}
    then \( \Phi \) maps the ball centered at \( 0 \) of radia \( r \) to itself.

    The smallest positive root of \eqref{eq:phi_endo0} is
    \begin{equation}\label{eq:endo_r0}
        r = \frac{1 - 2\gamma\beta - \sqrt{1-4\gamma\beta}}{2 \gamma^2 \beta} > 0
    \end{equation}

    \( r>1 \), unless \( M=0 \).
\end{lemma}
\begin{proof}
    \( r \) is positive:
    \[\underbrace{1-2\gamma\beta}_{\geq\frac12} > \underbrace{\sqrt{1-4\gamma\beta}}_{\geq0}\]
    \[\iff 4\gamma^2\beta^2 > 0 \quad\text{ which is true }\]
    And \( r>1 \) since the following statements are equivalent:
    \[1 - 2\gamma\beta - \sqrt{1-4\gamma\beta} \geq 2 \gamma^2 \beta\]
    \[1 - 2\gamma\beta(1 +  \gamma) \geq \sqrt{1-4\gamma\beta}\]
    \[\beta(1+\gamma)^2>1 \quad\text{ which is true}\]
\end{proof}

The bottom line is
\begin{lemma}\label{thm:endo}
    If
    \[\gamma\beta\leq\frac14, \gamma\geq\norm\Gamma, \beta\geq\norm B\]
    \[r = \frac{1 - 2\gamma\beta - \sqrt{1-4\gamma\beta}}{2 \gamma^2 \beta}\]
    \[\Omega = \{ X\in\mathfrak U; \norm X \leq r \}\]
    Then
    \[\Phi(\Omega)\subset\Omega\]
\end{lemma}

If we choose \( \gamma=\frac{1}{N}, \beta=\sqrt{M} \) we immediately get the following
\begin{thm}\label{thm:endo_nm}
    Let
    \begin{equation}\label{eq:phi_endo_nm_condition}
        M \leq \frac{1}{16} N^2
    \end{equation}
    \begin{equation}\label{eq:phi_endo_nm_radia}
        r = \frac12 N
        \left(
        \sqrt{NM}(\sqrt{N} - \sqrt{N-4\sqrt{M}}) - 2
        \right)
    \end{equation}
    \[\Omega = \{ X\in\mathfrak U; \norm X \leq r \}\]

    Then
    \( \Phi \) maps the ball \( \{ X\in\mathfrak U; \norm X \leq r \} \) into itself
    \[\Phi(\Omega)\subset\Omega\]
\end{thm}

Next step is to show that \( \Phi \) is a contraction in \( \Omega \).
Let \( \norm X, \norm Y \leq r \), \( \norm{X+Y} \leq 2r \) and also \( \gamma\geq\norm\Gamma \), \( \beta\geq\norm B \).

\begin{align*}
    \norm{\Phi(X) - \Phi(Y)}
    =& \norm{B\Gamma X - (\Gamma X)JB - (\Gamma X)J(B\Gamma X) - B\Gamma Y + (\Gamma Y)JB + (\Gamma Y)J(B\Gamma Y)} = \\
    =& \norm{B(\Gamma X - \Gamma Y) - (\Gamma X - \Gamma Y) JB + (\Gamma Y) J(B\Gamma Y) - (\Gamma X)J(B\Gamma X)} = \\
    =& \norm{B\Gamma(X-Y) - \Gamma(X-Y)JB + (\Gamma Y) J(B\Gamma Y) - (\Gamma X)J(B\Gamma X)} \leq \\
    \leq& 2\gamma\beta\norm{X-Y} + \norm{(\Gamma X)J(B\Gamma X) - (\Gamma Y) J(B\Gamma Y)}
\end{align*}
Since 
\begin{align*}
    &(\Gamma X - \Gamma Y)(P_jB(\Gamma X)P_j + P_jB(\Gamma Y)P_j) + \\
    + &(\Gamma X + \Gamma Y)(P_jB(\Gamma X)P_j - P_jB(\Gamma Y)P_j) = \\
= &2((\Gamma X)P_jB(\Gamma X)P_j- YP_jB(\Gamma Y)P_j)\end{align*}
\[(\Gamma X)J(B\Gamma X) - (\Gamma Y) J(B\Gamma Y)
= \frac12\left[\Gamma(X-Y)J(B\Gamma(X+Y)) + \Gamma(X+Y)J(B\Gamma(X-Y))\right]\]
\begin{align*}
    \norm{(\Gamma X)J(B\Gamma X) - (\Gamma Y) J(B\Gamma Y)}
    &= \frac12\norm{\left[\Gamma(X-Y)J(B\Gamma(X+Y)) + \Gamma(X+Y)J(B\Gamma(X-Y))\right]}\leq \\
    &\leq \gamma^2\beta r \norm{X-Y}
\end{align*}
\[\norm{\Phi(X) - \Phi(Y)} \leq (\gamma\beta(\gamma r + 2)\norm{X-Y}\]
for every \( \norm X, \norm Y \leq r \) and \( \gamma\geq\norm\Gamma, \beta\geq\norm B \).

\( \Phi \) will be a contraction in \( \Omega \) if \( \gamma\beta(\gamma r + 2) < 1 \), i.e.:
\[r < \frac{1-2\gamma\beta}{\gamma^2\beta}\]
This inequality holds.
\begin{TRIVIA}
        \[\frac{1-2\gamma\beta-\sqrt{1-4\gamma\beta}}{2\gamma^2\beta} < \frac{1-2\gamma\beta}{\gamma^2\beta}\]
        \[1-2\gamma\beta-\sqrt{1-4\gamma\beta} < 1+1-4\gamma\beta\]
        \[-2\gamma\beta<\sqrt{1-4\gamma\beta}\left(1+\sqrt{1-4\gamma\beta}\right)\]
        which is true
\end{TRIVIA}

We just proved
\begin{lemma}
    If
    \[\gamma\beta\leq\frac14, \gamma\geq\norm\Gamma, \beta\geq\norm B\]
    \[r = \frac{1 - 2\gamma\beta - \sqrt{1-4\gamma\beta}}{2 \gamma^2 \beta}\]
    \[\Omega = \{ X\in\mathfrak U; \norm X \leq r \}\]

    Then
    \( \Phi|_{\Omega}:\Omega\to\Omega \) is a contraction on a closed subset \( \Omega \) of a Banach space \( \mathfrak U \).
    And there exist unique solution of \eqref{eq:similarity}.
    Specifically, there is a single operator \( X_0\in\mathfrak U \), \( \norm{X_0} \leq r \),
    for which operators \( A-B \) and \( A-JX_0 \) are similar.
    \( X_0 \) can be found as a limit of a convergent sequence
    \[\{X_k\in\Omega; k\in\NN\}, \quad X_1 = 0, X_k = \Phi(X)_{k-1} \text{ for } k>1\]
\end{lemma}
And automatically
\begin{thm}
    Let the number \( M \) of unities in perturbation matrix \( \perturbmatrix{M}{N} \)
    satisfy the equation \eqref{eq:phi_endo1}: \( M \leq \frac{1}{16} N^2 \).
    And let
    \[ r = \frac12 N
        \left(
        \sqrt{NM}(\sqrt{N} - \sqrt{N-4\sqrt{M}}) - 2
        \right) \]

    Then there exist unique operator \( X_0 \), \( \norm{X_0} \leq r \), such that \( A - B \) and \( A - J X_0 \) are similar
    and have the same spectra
\end{thm}

\subsection{Eigenvalues estimation}
Projections \( P_1, P_2 \) break operator \( X_0 \) up into \( X_{ij}\in\mathfrak U_{ij}, i,j=\overline{1,2} \).
\( X_{11} = x_{11} I_{\mathcal X_1} \).

\[
    A-JX_0 \sim
    \left(
\begin{array}{c|c}
    N-x_{11} & 0 \\
    \hline
    0        & -X_{22}
\end{array}
\right)
\]

\begin{propose}
    \[ \spec{\almostallones{M}{N}}  = \left\{N - x_{11}\right\} \cup \spec{-X_{22}} \]
    \[ \max_{\lambda\in\spec{-X_{22}}} \left|\lambda\right| \leq r \]
\end{propose}
\begin{proof}
    \[ \spec{\almostallones{M}{N}} = \spec{A-B} = \spec{A-JX_0} = \{N - x_{11}\} \cup \spec{-X_{22}} \]
    \[ \max_{\lambda\in\spec{-X_{22}}} \left|\lambda\right| = \spr{-X_{22}} \leq \norm{-X_{22}} \leq \norm{X_0} \leq r \]
\end{proof}

\begin{lemma}
    If
    \[\gamma\beta\leq\frac14, \gamma\geq\norm\Gamma, \beta\geq\norm B\]
    \[r = \frac{1 - 2\gamma\beta - \sqrt{1-4\gamma\beta}}{2 \gamma^2 \beta}\]

    Then $r>0$ and there is
	\[ \lambda_0\in\spec{A-B} \cap \left[N-r,N+r\right] \neq\emptyset \]
	and
	\[ \spec{A-B}\backslash\{\lambda_0\} \subset \left[-r,r\right] \]
\end{lemma}
\begin{thm}
    Let \( \almostallones{M}{N} \) be a matrix of dimension \( N>0 \) consisting of zeroes and ones,
    and let \( M \) be the number of zeroes in \( \almostallones{M}{N} \).
    And let
    \[ M < \frac{1}{16} N^2 \]
    \[ r = \frac12 N
        \left(
        \sqrt{NM}(\sqrt{N} - \sqrt{N-4\sqrt{M}}) - 2
        \right) \]

    Then $r>0$ and at least one eigenvalue \( \lambda_0 \) of \( \almostallones{M}{N} \) lies in the interval \(\left[N-r,N+r\right]\)
	and the rest of the spectra is contained in the interval \( \left[-r,r\right] \)

    \[ \left|\lambda_0 - N\right| \leq r \]
    \[ \left|\lambda\right| \leq r \quad \text{ for } \lambda\in\spec{\almostallones{M}{N}}\backslash\{\lambda_0\} \]
\end{thm}

\section{Splitting the operator}
Consider again the equation \( \Phi(X) = X \).
Operator \( \Phi(X) \) can be written as an operators matrix:

\[
    \Phi X \sim
    \begin{pmatrix}
        \Phi_{11}(X) & \Phi_{12}(X) \\
        \Phi_{21}(X) & \Phi_{22}(X)
    \end{pmatrix}
\]
\begin{subequations}
    \begin{align}
        \label{eq:split11}
        & \Phi_{11}(X) = \Psi_{11}(X_{21}) = -\frac1N B_{12}X_{21} + B_{11} \\
        \label{eq:split12}
        & \Phi_{12}(X) = \Psi_{12}(X_{12}) = \frac{1}{N^2} X_{12}B_{21}X_{12} -
                                   \frac1N\left(X_{12}B_{22} +
                                   B_{11}X_{12}\right) + B_{12} \\
        \label{eq:split21}
        & \Phi_{21}(X) = \Psi_{21}(X_{21}) = -\frac{1}{N^2} X_{21}B_{12}X_{21} -
                                   \frac1N\left(X_{21}B_{11} +
                                   B_{22}X_{21}\right) +
                                   B_{21} \\
        \label{eq:split22}
        & \Phi_{22}(X) = \Psi_{22}(X_{12}) = \frac1N B_{21}X_{12} + B_{22}
    \end{align}
\end{subequations}

From these equalities it is clear that if we only had
\( {\Psi_{12}(X_{12}^o) = X_{12}^o} \),
\( {\Psi_{21}(X_{21}^o) = X_{21}^o} \),
then it would give us \( X_{11}^o, X_{22}^o \), such that
\( \Phi(X^o) = X^o \) for
\( X^o \sim
\left(\begin{smallmatrix}
    X_{11}^o & X_{12}^o \\
    X_{21}^o & X_{22}^o
\end{smallmatrix}\right) \).
Let's see if we can refine our results using this fact.

It is easily shown
that \eqref{eq:split12}, \eqref{eq:split21}
each have unique stationary points \( X_{12}^o, X_{21}^o \)
in corresponding \( 0 \)-centered balls.
These solutions are given by Banach' fix-point theorem.

These separated equations have the same convergence conditions
and soltuions' norms bounds as equation \( \Phi(X)=X \) from previous sections.

\[ \norm{\Psi_{12}(X_{12})} \leq
    \frac{1}{N^2}\beta\norm{X_{12}}^2 + \frac2N \beta\norm{X_{12}} + \beta \]
\[ \frac{1}{N^2}\beta r^2 + \frac{2\beta - N}{N} r + \beta \leq 0 \]
\[
    \Delta = 1 - \frac{4\beta}{N} \geq 0
    \text{ iff }
    \beta \leq \frac14 N
\]
\[
    r_0 = \frac{N^2}{\beta}
          \left(
                \frac{N-2\beta}{N} - \sqrt{1 - \frac{4\beta}{N}}
          \right)
    \]

At the same time we can derive new estimates for
\( \norm{X_{11}^o}, \norm{X_{22}^o} \)
(which define the spectra and are of particular interest)

\[ \norm{X_{11}^o}, \norm{X_{22}^o}
   \leq \frac{\beta}{N}(r_0 + 1)
   \leq \frac14 (r_0 + 1)\]




\section{Future work}
This article gives bounds for eigenvalues expressed in terms of the dimension of the matrix and the number of unities in perturbation.
It gives also recursive formula which allows for computation of diagonalizing transformation matrix for \( \allones{N} \)
which makes it possible to refine the bounds (for the norm of the perturbation matrix and thus for convergence radius)
for any specific matrix by applying straightforward generic algorithm (TODO: stability of numerical method?).
\end{document}
